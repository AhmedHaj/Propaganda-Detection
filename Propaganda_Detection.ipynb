{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Detection of Propaganda Techniques in News Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project Type: 2\n",
    "\n",
    "Group: 19\n",
    "\n",
    "Ahmed Haj Abdel Khaleq 8223727\n",
    "\n",
    "Malissa Ekanayake 6927445"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Timesheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Ahmed H.               | Task            | Hours spent     | Challenge |\n",
    "|----------------------------|-----------------|-----------------|-----------------|\n",
    "                |            | Learning PyTorch | 6  | Tried (and failed at) learning PyTorch in order to implement Logistic Regression using Pytorch |                           \n",
    "|                  | Learning Keras         | 2          | Tried (and sort of succeeded at) learning Keras in order to implement Logistic Regression using Keras       |\n",
    "|                  | Dataset Cleaning        | 3          | Made sense of and attempted to modify and clean up the dataset for Task 1 of our project using techniques such as NLP  |\n",
    "|                  | Reading into undersampling and oversampling        | 1          | Task 2's dataset is smaller than that of Task 1's, so I looked into methods to improve that  |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Malissa E.              | Task            | Hours spent        | Challenge |\n",
    "|----------------------------|-----------------|-----------------|-----------------|\n",
    " |            | Read Article Ref[1] which talks about Decision Trees vs Logistic Regression | 2  | We haven't used Decision Trees in detail in class, so I had to learn what they are in terms of Machine Learning |                           \n",
    "|                  | Implemented Decision Trees using SKLearn         | 5          | I looked at alternatives to use when implementing Decision Trees, but found that SKLearn would be the best for our project because we are already using a different implementation for Logistic Regression, and we have not implemented Decision Trees in any of the Notebooks       |\n",
    "|                  | Dataset Cleaning        | 3          | Made sense of and attempted to modify and clean up the dataset for Task 2 of our project using techniques such as NLP  |\n",
    "|                  | NLP experimentation       | 3          | Experimented with different NLP techniques on our Task 2 Dataset to make up for the fact that it's unbalanced |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is based on the SemEval 2020 competetition, Task 11 \"Detection of Propaganda Techniques in News Articles\" [0]. It is divided into 2 tasks: \n",
    "\n",
    "Task 1: Detect whether or not a given sequence of characters is propaganda\n",
    "\n",
    "Task 2: Given a sequence of characters that is propaganda, classify the type of propaganda that it belongs to.\n",
    "\n",
    "\n",
    "The problem studied is, as the title says, detecting propaganda in news articles using machine learning. \n",
    "\n",
    "Context: Many news articles today, especially considering today's political climate, often employ propaganda techniques in their articles in order to sway the reader into thinking one way or another. Therefore, it is the reader's duty to make sure that they are not being tricked into holding a certain political opinion by being able to detect propaganda techniques in news article that they read. However, it is not an easy task to know when a news article contains propaganda in it. As such, if we could automatically detect when a news article contains propaganda, we would make it easier for readers to know which news sources to trust, and which to avoid.\n",
    "\n",
    "Link to AI: In order to automate this task, we decided to use AI to automatically detect whether or not a news article contains propaganda. In this notebook, we are comparing Decision Trees and 2 different implementations of Logistic Regression.\n",
    "\n",
    "Why is it important: It's important because it helps users get better sources for news, and to know whether or not a news article is worth reading. It also helps news article authors to up the quality of their articles, because even people who write news articles have biases.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dataset Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where does it come from: https://propaganda.qcri.org/semeval2020-task11/ (note that you need to register first, and then they will email you the dataset)\n",
    "\n",
    "What does it contain: A baselines file, A datasets file, and a tools file. \n",
    "\n",
    "The baselines file contains baselines which ensure that the dataset has been labelled correctly, and the tools folder contains tools which help with organizing the results in a way that is fit for the actual competition. (Not important for the project)\n",
    "\n",
    "The datasets file contains:\n",
    "\n",
    "1) a README file which explains how the data is laid out. \n",
    "\n",
    "2) The train-articles folder in which the articles themselves are stored in as .txt files \n",
    "\n",
    "3) A train-labels-task1 folder which contains labels for each article where the article name, character on which propaganda starts, and character on which propaganda ends are specified\n",
    "\n",
    "4) A train-lables-task2 folder which contains labels for each article where the article name, type of propaganda, character on which propaganda starts, and character on which propaganda ends are specified\n",
    "\n",
    "A test set was not included (will be released in March), so we had to adopt a technique that was used in the notebook where we split the dataset, 90% to 10%. \n",
    "\n",
    "\n",
    "## Size:\n",
    "\n",
    "Overall: 550 news articles, but when treating the sentences themselves as input, the dataset becomes of size 10940 \n",
    "\n",
    "For Task 1: Using the input dataset, we had 5470 propaganda sentences. However, by adding the same amount sentences which were NOT tagged as propaganda, we effictively doubled the dataset and made it balanced (So no need to oversample/undersample). The final size of the dataset for Task 1 is 10940.\n",
    "\n",
    "For Task 2: Since Task 2 only works on sentences labelled as propaganda, the dataset size for Task 2 is 5470. (We have looked at undersampling and oversampling, however we decided to try NLP techniques on it instead because it's something that we haven't tried before)\n",
    "\n",
    "\n",
    "## Was cleaning required?\n",
    "\n",
    "Since the dataset was all over the place (in 3 different folders, and even then the labels weren't even in the same place as the news articles!), a lot of cleaning was required. \n",
    "\n",
    "**Step 1A: First off, we had to gather the labels from the Task 1 folder, read them, and place them into a dict type (propTagsSpan) where the article number is the key, and a list containing the characters where the propaganda starts and ends as values.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['111111111 265 323 ', '111111111 1795 1935 ', '111111111 149 157 ', '111111111 1069 1091 ', '111111111 1334 1462 ', '111111111 1577 1616 ', '111111111 2023 2086 ']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "newsArticles = os.listdir(\"datasets/train-articles/\") # this is where our news articles are located\n",
    "propagandaTagsSpan = os.listdir(\"datasets/train-labels-task1-span-identification\") # this is where our tags are located\n",
    "newsArticles.sort()\n",
    "propagandaTagsSpan.sort()\n",
    "propTagsSpan = {} # Dictionary containing the news article number as a key, and propoganda snip as values\n",
    "\n",
    "for i in range(len(newsArticles)):\n",
    "    article = newsArticles[i]\n",
    "    articleNoExt = os.path.splitext(article)[0] # remove the .txt file extension ([2])\n",
    "    newsArticles[i] = articleNoExt # replace newsArticles[i] with the same name but without the .txt extension\n",
    "    articleNo = articleNoExt.replace('article', '') # remove 'article' to leave just the number\n",
    "    \n",
    "    tagPath = \"datasets/train-labels-task1-span-identification/\"+ articleNoExt + \".task1-SI.labels\"\n",
    "    with open(tagPath) as f:\n",
    "        tags = f.readlines()\n",
    "        # replace \\t and \\n in tags with \" \" for easier processing later on\n",
    "        for i in range(len(tags)):\n",
    "            tag = tags[i]\n",
    "            tag = tag.replace(\"\\t\", \" \")\n",
    "            tag = tag.replace(\"\\n\", \" \")\n",
    "            tags[i] = tag \n",
    "        propTagsSpan[articleNoExt] =  tags\n",
    "    f.close()\n",
    "\n",
    "print(propTagsSpan[newsArticles[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1B: Do the same thing as 1A, but for Task 2, from the Task 2 dataset folder.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['  Appeal_to_Authority 265 323 ', '  Appeal_to_Authority 1795 1935 ', '  Doubt 149 157 ', '  Repetition 1069 1091 ', '  Appeal_to_fear-prejudice 1334 1462 ', '  Appeal_to_fear-prejudice 1577 1616 ', '  Appeal_to_fear-prejudice 1856 1910 ', '  Appeal_to_fear-prejudice 2023 2086 ']\n"
     ]
    }
   ],
   "source": [
    "propagandaTagsTechnique = os.listdir(\"datasets/train-labels-task2-technique-classification\") # this is where our tags are located for techique\n",
    "## note: in span-identification, techniques that overlap are not split\n",
    "propagandaTagsTechnique.sort()\n",
    "propTagsTechnique = {} # Dictionary containing news article as key, and technique as value\n",
    "\n",
    "for i in range(len(newsArticles)):\n",
    "    article = newsArticles[i]\n",
    "    articleNoExt = os.path.splitext(article)[0] # remove the .txt file extension ([2])\n",
    "    newsArticles[i] = articleNoExt # replace newsArticles[i] with the same name but without the .txt extension\n",
    "    articleNo = articleNoExt.replace('article', '') # remove 'article' to leave just the number\n",
    "    \n",
    "    tagPath = \"datasets/train-labels-task2-technique-classification/\"+ articleNoExt + \".task2-TC.labels\"\n",
    "    \n",
    "    with open(tagPath) as f:\n",
    "        tags = f.readlines()\n",
    "        # replace \\t and \\n in tags with \" \" for easier processing later on\n",
    "        for i in range(len(tags)):\n",
    "            tag = tags[i]\n",
    "            tag = tag.replace(articleNo, \" \")\n",
    "            tag = tag.replace(\"\\t\", \" \")\n",
    "            tag = tag.replace(\"\\n\", \" \")\n",
    "            tags[i] = tag \n",
    "            #print(tag)\n",
    "        propTagsTechnique[articleNoExt] = tags\n",
    "    f.close()\n",
    "    \n",
    "print(propTagsTechnique[newsArticles[0]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2 : Using the dict created in Step 1, read all of the sentences that have been annotated as \"propaganda\" from the 'train-articles' folder, and put them in a list which will be named 'propSentencesSpan'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The next transmission could be more pronounced or stronger\n"
     ]
    }
   ],
   "source": [
    "propSentencesSpan = []\n",
    "\n",
    "for article in newsArticles:\n",
    "    artPath = \"datasets/train-articles/\" + article + \".txt\"\n",
    "    \n",
    "    tags = propTagsSpan[article]\n",
    "    \n",
    "    with open(artPath, encoding=\"utf-8\") as f:\n",
    "        wholeArticle = f.read()\n",
    "        for tag in tags:\n",
    "            tag = tag.split()\n",
    "            start = int(tag[1])\n",
    "            end = int(tag[2])\n",
    "            \n",
    "            taggedLine = wholeArticle[start:end]\n",
    "            taggedLine = taggedLine.replace(\"\\n\", \" \")\n",
    "            taggedLine = taggedLine.replace(\"\\t\", \" \")\n",
    "          \n",
    "            propSentencesSpan.append(taggedLine)\n",
    "    f.close()\n",
    "    \n",
    "print(propSentencesSpan[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Create a dictionary with the keys being the propoganda sentences, and the values being their associated propoganda type. This is to setup our data to be put into a Pandas dataframe for Task 2.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary with sentences as keys and technique as value\n",
    "propagandaTechniques = {}\n",
    "propagandaTechniques[\"Sentence\"] = []\n",
    "propagandaTechniques[\"Technique\"] = []\n",
    "\n",
    "for article in newsArticles:\n",
    "    artPath = \"datasets/train-articles/\" + article + \".txt\"\n",
    "    \n",
    "    tags = propTagsTechnique[article]\n",
    "    with open(artPath, encoding=\"utf-8\") as f:\n",
    "        wholeArticle = f.read()\n",
    "        for tag in tags:\n",
    "            tag = tag.split()\n",
    "            propagandaTechniques[\"Technique\"].append(tag[0]) # add technique to dictionary\n",
    "            #print(tag[0])\n",
    "            start = int(tag[1])\n",
    "            end = int(tag[2])\n",
    "            taggedLine = wholeArticle[start:end]\n",
    "            taggedLine = taggedLine.replace(\"\\n\", \" \")\n",
    "            taggedLine = taggedLine.replace(\"\\t\", \" \")\n",
    "            #print(article + \" \" + taggedLine)\n",
    "            propagandaTechniques[\"Sentence\"].append(taggedLine) # add snippet to dictionary\n",
    "    f.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4: Using the list of propaganda senteces that we've gathered, create another list, 'notPropSentences' which will contain sentences from the articles that have not been annotated as propaganda. This will be used for Task 1.**\n",
    "\n",
    "Note: Since we're relying on the actual news article now instead of labelled characters, we need to sentence_tokenize each article, and go through each sentence. If a sentence or phrase that is in our list of propaganda sentences is inside or the same as the current sentence, then it does not get added to the list of non propaganda sentences and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5470\n",
      "5470\n",
      "An outbreak of both bubonic plague, which is spread by infected rats via flea bites, and pneumonic plague, spread person to person, has killed more than 200 people in the Indian Ocean island nation since August.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "notPropSentences = []\n",
    "\n",
    "count = 0\n",
    "maxNum = len(propSentencesSpan) # we want an equal number of propaganda and non-propaganda sentences to create a balanced training set\n",
    "for article in newsArticles:\n",
    "    artPath = \"datasets/train-articles/\" + article + \".txt\"\n",
    "    with open(artPath, encoding=\"utf-8\") as f:\n",
    "        wholeArticle = f.read()\n",
    "        \n",
    "        # Remove SPANNED lines of propoganda from articles to detect non-propoganda lines\n",
    "        currentPropSentences = []\n",
    "        tags = propTagsSpan[article]\n",
    "        for tag in tags:\n",
    "            tag = tag.split()\n",
    "            start = int(tag[1])\n",
    "            end = int(tag[2])\n",
    "            taggedLine = wholeArticle[start:end]\n",
    "            taggedLine = taggedLine.replace(\"\\n\", \" \")\n",
    "            taggedLine = taggedLine.replace(\"\\t\", \" \")\n",
    "            currentPropSentences.append(taggedLine)\n",
    "        \n",
    "        sentences = nltk.sent_tokenize(wholeArticle)\n",
    "        for sentence in sentences:\n",
    "            if(count == maxNum):\n",
    "                break\n",
    "            notProp = True\n",
    "            sentence = sentence.replace(\"\\n\", \" \")\n",
    "            sentence = sentence.replace(\"\\t\", \" \")\n",
    "            for propSentence in currentPropSentences:\n",
    "                if(propSentence in sentence):\n",
    "                    notProp = False\n",
    "                    \n",
    "            if(notProp): \n",
    "                count +=1\n",
    "                notPropSentences.append(sentence)\n",
    "\n",
    "print(len(propSentencesSpan))\n",
    "print(len(notPropSentences))\n",
    "print(notPropSentences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5A: Merge both 'propSentences' and 'notPropSentences' into one list which will serve as our dataset for Task 1.**\n",
    "\n",
    "Note: At first, we attempted to do POS tagging on the sentences, and then use a Vectorizer on the POS tagged sentences, and use that instead of just doing a Vectorizer on the sentences directly. However we found that using a countVectorizer on the sentences as they are yielded higher accuracy. We believe this is because when it comes to detecting propaganda, the words used are more important than the structure of the sentence itself because some words are more prevalent in propaganda sentences than in non-propaganda sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Propaganda</th>\n",
       "      <th>Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>The next transmission could be more pronounced...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>when (the plague) comes again it starts from m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>appeared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>a very, very different</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>He also pointed to the presence of the pneumon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Propaganda                                           Sentence\n",
       "0        Yes  The next transmission could be more pronounced...\n",
       "1        Yes  when (the plague) comes again it starts from m...\n",
       "2        Yes                                           appeared\n",
       "3        Yes                             a very, very different\n",
       "4        Yes  He also pointed to the presence of the pneumon..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# In order to use pandas, we have to create a dict where we will store as values, which we can then convert into a Pandas DataFrame\n",
    "sentencesToCSV = {}\n",
    "sentencesToCSV[\"Propaganda\"] = []\n",
    "sentencesToCSV[\"Sentence\"] = []\n",
    "\n",
    "# A special dict for the Keras Logistic Regression Model:\n",
    "\n",
    "sentencesToCSVKeras = {}\n",
    "sentencesToCSVKeras[\"Propaganda\"] = []\n",
    "sentencesToCSVKeras[\"Sentence\"] = []\n",
    "\n",
    "for sentence in propSentencesSpan: \n",
    "    sentencesToCSV[\"Propaganda\"].append(\"Yes\")\n",
    "    sentencesToCSV[\"Sentence\"].append(sentence) \n",
    "    \n",
    "    sentencesToCSVKeras[\"Propaganda\"].append(1)\n",
    "    sentencesToCSVKeras[\"Sentence\"].append(sentence)\n",
    "    \n",
    "\n",
    "for sentence in notPropSentences:  \n",
    "    sentence.replace(\"\\n\", \" \")\n",
    "    sentence.replace(\"\\t\", \" \")\n",
    "    \n",
    "    sentencesToCSV[\"Propaganda\"].append(\"No\")\n",
    "    sentencesToCSV[\"Sentence\"].append(sentence) \n",
    "    \n",
    "    sentencesToCSVKeras[\"Propaganda\"].append(0)\n",
    "    sentencesToCSVKeras[\"Sentence\"].append(sentence)\n",
    "\n",
    "\n",
    "df = pd.DataFrame.from_dict(sentencesToCSV)\n",
    "dfKeras = pd.DataFrame.from_dict(sentencesToCSVKeras)\n",
    "\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5B: Create the Pandas dataframe for Task 2 from the dict that we made in Step 3.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Technique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>The next transmission could be more pronounced...</td>\n",
       "      <td>Appeal_to_Authority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>when (the plague) comes again it starts from m...</td>\n",
       "      <td>Appeal_to_Authority</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>appeared</td>\n",
       "      <td>Doubt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>a very, very different</td>\n",
       "      <td>Repetition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>He also pointed to the presence of the pneumon...</td>\n",
       "      <td>Appeal_to_fear-prejudice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence                 Technique\n",
       "0  The next transmission could be more pronounced...       Appeal_to_Authority\n",
       "1  when (the plague) comes again it starts from m...       Appeal_to_Authority\n",
       "2                                           appeared                     Doubt\n",
       "3                             a very, very different                Repetition\n",
       "4  He also pointed to the presence of the pneumon...  Appeal_to_fear-prejudice"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pandas DataFrame for propoganda snippet and propoganda technique\n",
    "\n",
    "df_techniques = pd.DataFrame.from_dict(propagandaTechniques)\n",
    "df_techniques.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6A: Similar to what we have done in Notebook 3, we are going to split the data such that 90% is used for training and 10% is used for testing for Task 1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I think that will reveal a whole other layer of who knew what, where and when.\n",
      "No\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_sentences, test_sentences, train_tags, test_tags = train_test_split(df[\"Sentence\"],\n",
    "                                                                      df[\"Propaganda\"],\n",
    "                                                                      test_size=0.1, \n",
    "                                                                      random_state=10,\n",
    "                                                                      stratify=df[\"Propaganda\"])\n",
    "\n",
    "train_tags = train_tags.to_numpy()\n",
    "train_sentences = train_sentences.to_numpy()\n",
    "# Testing set (what we will use to test the trained model)\n",
    "test_tags = test_tags.to_numpy()\n",
    "test_sentences = test_sentences.to_numpy()\n",
    "\n",
    "\n",
    "print(train_sentences[1])\n",
    "print(train_tags[1])\n",
    "\n",
    "\n",
    "# Do the same thing for the Keras df\n",
    "\n",
    "train_sentences, test_sentences, train_tags, test_tags = train_test_split(dfKeras[\"Sentence\"],\n",
    "                                                                      dfKeras[\"Propaganda\"],\n",
    "                                                                      test_size=0.1, \n",
    "                                                                      random_state=10,\n",
    "                                                                      stratify=dfKeras[\"Propaganda\"])\n",
    "\n",
    "train_tags_keras = train_tags.to_numpy()\n",
    "train_sentences_keras = train_sentences.to_numpy()\n",
    "# Testing set (what we will use to test the trained model)\n",
    "test_tags_keras = test_tags.to_numpy()\n",
    "test_sentences_keras = test_sentences.to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6B: Splitting the data such that 90% is used for training and 10% is used for testing for Task 2.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White House Leaker\n",
      "Name_Calling,Labeling\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train2_sentences, test2_sentences, train2_tags, test2_tags = train_test_split(df_techniques[\"Sentence\"],\n",
    "                                                                      df_techniques[\"Technique\"],\n",
    "                                                                      test_size=0.1, \n",
    "                                                                      random_state=10,\n",
    "                                                                      stratify=df_techniques[\"Technique\"])\n",
    "\n",
    "train2_tags = train2_tags.to_numpy()\n",
    "train2_sentences = train2_sentences.to_numpy()\n",
    "# Testing set (what we will use to test the trained model)\n",
    "test2_tags = test2_tags.to_numpy()\n",
    "test2_sentences = test2_sentences.to_numpy()\n",
    "\n",
    "\n",
    "print(train2_sentences[40])\n",
    "print(train2_tags[40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 7A: Vectorizer on the df for Task 1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9846, 13239)\n",
      "(9846,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "train_counts = count_vect.fit_transform(train_sentences)\n",
    "test_counts = count_vect.transform(test_sentences)\n",
    "print(train_counts.shape)\n",
    "print(train_tags.shape)\n",
    "\n",
    "\n",
    "# Same thing but for Keras\n",
    "\n",
    "count_vect_keras = CountVectorizer()\n",
    "train_counts_keras = count_vect_keras.fit_transform(train_sentences_keras).toarray()\n",
    "test_counts_keras = count_vect_keras.transform(test_sentences_keras).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 7B: Vectorizer on the df for Task 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect2 = CountVectorizer()\n",
    "train2_counts = count_vect2.fit_transform(train2_sentences)\n",
    "test2_counts = count_vect2.transform(test2_sentences)\n",
    "\n",
    "# For Keras. Transforms String labels to integer. Basically a one hot encoder.\n",
    "from sklearn.preprocessing import LabelBinarizer # from [4]\n",
    "\n",
    "encoder = LabelBinarizer()\n",
    "\n",
    "train2_tags_keras = encoder.fit_transform(train2_tags)\n",
    "test2_tags_keras = encoder.fit_transform(test2_tags)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Details of Methods (Approaches) Used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5A. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A) Logistic Regression: Logistic Regression fits a single line to divide the space exactly into two (binomial LR). [1]\n",
    "\n",
    "For Task 1, Binomial Logistic Regression was used. For Task 2, Multinomial Logistic Regression was used because we need to divide the space into more than 2 parts since we have multiple classes instead of only 2 classes.\n",
    "\n",
    "B) The reason why we decided to use Logistic Regression is because we think it would function really well for the goal of the project. Since our project is divided into 2 Tasks, a Binary Classification Task and a Multinomial Classification. We believe that it will perform better than Decision Trees in Task 1, while for Task 2, we think their performance would be close to each other's.\n",
    "\n",
    "C) Keras was used just to learn a new package. But we ran into some issues with its implementation so we are also using SKlearn just so that our knowledge (or lack of) when implementing Logistic Regression using Keras isn't a factor. \n",
    "\n",
    "\n",
    "(Initially we were using PyTorch, but it we couldn't get it to work at all so we used an SKlearn alternative just so that we can finish the project and not waste time) \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the Keras Binomial Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/Ahmed/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/Ahmed/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/Ahmed/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/Ahmed/opt/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/Ahmed/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/Ahmed/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Activation \n",
    "from keras import backend as K\n",
    "\n",
    "# The functions below were taken from [3]\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "keras_lr_1 = Sequential() \n",
    "keras_lr_1.add(Dense(input_dim = 13239, units = 1)) # 13229 is the shape of the df for task 1, 1 is output dimension of the test tag which is 0 or 1 \n",
    "keras_lr_1.add(Activation('relu'))\n",
    "keras_lr_1.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy', recall_m, precision_m])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the SKLearn Binomial Logistic Regression Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import datetime\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "\n",
    "# What we will use for LogisticRegression\n",
    "clf_lr = LogisticRegression(solver='lbfgs', multi_class=\"ovr\", max_iter=1000, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the Multinomial Keras Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_lr_2 = Sequential() \n",
    "keras_lr_2.add(Dense(input_dim = 7275, units = 14)) # 13229 is the shape of the df, 1 is output dimension of the test tag which is 0 or 1 \n",
    "keras_lr_2.add(Activation('relu'))\n",
    "keras_lr_2.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy', recall_m, precision_m])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up the Multinomial SKLearn Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What we will use for LogisticRegression\n",
    "clf_lr2 = LogisticRegression(solver='lbfgs', multi_class=\"multinomial\", max_iter=1000, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the training method for the SKLearn Logistic Regression Models (from the notebooks):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(clf, X_train, y_train, epochs=10):\n",
    "    scores = []\n",
    "    print(\"Starting training...\")\n",
    "    for i in range(1, epochs + 1):\n",
    "        print(\"Epoch:\" + str(i) + \"/\" + str(epochs) + \" -- \" + str(datetime.datetime.now()))\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_train, y_train)\n",
    "        scores.append(score)\n",
    "    print(\"Done training.\")\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining methods to calculate precision and recall for SKLearn (from notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(actualTags, predictions, classOfInterest):\n",
    "    actualCounter = 0\n",
    "    predCounter = 0\n",
    "    for i in range(len(predictions)):\n",
    "        if classOfInterest == predictions[i]:\n",
    "            predCounter += 1\n",
    "            if classOfInterest == actualTags[i]:\n",
    "                actualCounter += 1\n",
    "    return actualCounter/predCounter\n",
    "\n",
    "def recall(actualTags, predictions, classOfInterest):\n",
    "    actualTagCounter = 0\n",
    "    predictionsCounter = 0\n",
    "    for i in range(len(predictions)):\n",
    "        if classOfInterest == actualTags[i]:\n",
    "            actualTagCounter += 1\n",
    "            if classOfInterest == predictions[i]:\n",
    "                predictionsCounter += 1\n",
    "   \n",
    "    return predictionsCounter/actualTagCounter\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Keras Binomial LR model and printing the accuracy, precision, and recall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/Ahmed/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/Ahmed/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/Ahmed/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 9846 samples, validate on 1094 samples\n",
      "Epoch 1/1\n",
      "WARNING:tensorflow:From /Users/Ahmed/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/Ahmed/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/Ahmed/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/Ahmed/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/Ahmed/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "9846/9846 [==============================] - 2s 176us/step - loss: 0.7594 - acc: 0.5952 - recall_m: 0.3465 - precision_m: 0.5644 - val_loss: 0.6281 - val_acc: 0.7559 - val_recall_m: 0.7225 - val_precision_m: 0.7736\n",
      "Accuracy: 0.7559414990859232\n",
      "Precision: 0.7743745277307151\n",
      "Recall: 0.7208834043150628\n"
     ]
    }
   ],
   "source": [
    "keras_lr_1.fit(train_counts, train_tags_keras, epochs= 1, batch_size=128, verbose=1, validation_data=(test_counts, test_tags_keras))\n",
    "\n",
    "loss, accuracy1_keras, recall1_keras, precision1_keras = keras_lr_1.evaluate(test_counts, test_tags_keras, verbose=0)\n",
    "\n",
    "print(\"Accuracy:\", accuracy1_keras)\n",
    "print(\"Precision:\", precision1_keras)\n",
    "print(\"Recall:\", recall1_keras)\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the SKLearn Binomial LR model and printing the accuracy, recall, and precision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch:1/1 -- 2019-12-06 23:33:35.803248\n",
      "Done training.\n",
      "Accuracy: [0.9313426772293317]\n"
     ]
    }
   ],
   "source": [
    "clf_lr_score = train_model(clf_lr, train_counts, train_tags, 1)\n",
    "y_pred = clf_lr.predict(test_counts)\n",
    "print(\"Accuracy:\",clf_lr_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Keras Multinomial LR Model and printing the score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5732 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "5732/5732 [==============================] - 1s 194us/step - loss: 2.6675 - acc: 0.2406 - recall_m: 0.0686 - precision_m: 0.1063 - val_loss: 2.1430 - val_acc: 0.3203 - val_recall_m: 0.1256 - val_precision_m: 0.1343\n",
      "Accuracy: 0.3202511773472491\n",
      "Precision: 0.13707748666008002\n",
      "Recall: 0.12558869699387573\n"
     ]
    }
   ],
   "source": [
    "keras_lr_2.fit(train2_counts, train2_tags_keras, epochs= 1, batch_size=128, verbose=1, validation_data=(test2_counts, test2_tags_keras))\n",
    "\n",
    "loss, accuracy2_keras, recall2_keras, precision2_keras = keras_lr_2.evaluate(test2_counts, test2_tags_keras, verbose=0)\n",
    "\n",
    "print(\"Accuracy:\", accuracy2_keras)\n",
    "print(\"Precision:\", precision2_keras)\n",
    "print(\"Recall:\", recall2_keras)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch:1/1 -- 2019-12-06 23:33:37.561765\n",
      "Done training.\n",
      "[0.8565945568736916]\n"
     ]
    }
   ],
   "source": [
    "clf_lr_score2 = train_model(clf_lr2, train2_counts, train2_tags, 1)\n",
    "print(clf_lr_score2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5B. Decision Trees\n",
    "\n",
    "A) Decision Trees: Decision Trees bisect the space into smaller and smaller regions. [1]\n",
    "\n",
    "\n",
    "B) The reason why we decided to use Decision Trees is because it's a discriminative learner just like Logistic Regression. However it's designed with multinomial classification in mind, so it's interesting to see how it compares to Binomial Logistic Regression in Task 1. (We predict that Binomial LR will perform better in Task 1, while they will perform similarly in Task 2)\n",
    "\n",
    "C) SKLearn was used to implement Decision Trees to keep things simple. We chose SKLearn because Decision Trees are already a new kind of discriminative learner to us, so we did not want to choose something too complicated when implementing them\n",
    "\n",
    "\n",
    "\n",
    "**Implementing and printing the score, precision, and recall for precision trees for Task 1:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7020109689213894\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-b1edf00f8228>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Precision:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Yes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Recall:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Yes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-a9390b6b6453>\u001b[0m in \u001b[0;36mprecision\u001b[0;34m(actualTags, predictions, classOfInterest)\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mclassOfInterest\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mactualTags\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                 \u001b[0mactualCounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mactualCounter\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mpredCounter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactualTags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassOfInterest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# Create Decision Tree classifer object\n",
    "clf_dt = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf_dt = clf_dt.fit(train_counts,train_tags)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf_dt.predict(test_counts)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(test_tags, y_pred))\n",
    "\n",
    "print(\"Precision:\", precision(test_tags, y_pred, \"Yes\"))\n",
    "print(\"Recall:\", recall(test_tags, y_pred, \"Yes\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementing and printing the score, precision, and recall for precision trees for Task 2:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# Create Decision Tree classifer object\n",
    "clf_dt2 = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf_dt2 = clf_dt2.fit(train2_counts,train2_tags)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf_dt2.predict(test2_counts)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\", metrics.accuracy_score(test2_tags, y_pred))\n",
    "\n",
    "print(\"Precision:\", precision(test2_tags, y_pred, \"Name_Calling,Labeling\"))\n",
    "print(\"Recall:\", recall(test2_tags, y_pred, \"Name_Calling,Labeling\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where our usage of the Keras models stopped. The scores for the Keras models were significantly lower than that of their SKLearn counterparts, and we believe it might be because our implementation was poor, so we decided to drop it entirely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A) Our datasets consisted of the sentence and whether or not it's propaganda for Task 1. and For Task 2, the dataset consisted of the sentence, and the type of propaganda used in the sentence. \n",
    "\n",
    "A new version of both the train and the test sentences are created with any non-alphanumeric tokens and any *stopwords* removed for Task 2. \n",
    "\n",
    "B) Applying NLP Techique 'Removal of Stopwords and Non-Alphanumerical Characters for Task 2 Dataset. A stopword is a word that is too common to be deemed useful when training or testing a model. In nltk, we will use the stopwords list available as a guide on what to remove. We believe that the structure of a sentence is more important than the actual words used to make up a sentence.\n",
    "\n",
    "C) No Features got removed because our dataset consists only of sentences and its propaganda status for task 1, or propaganda type for task 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying NLP Techniques on our already made dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Stopwords and non-alphanumeric characters (from the notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# From a given train or test set, returns a new version of the set (as a numpy array)\n",
    "# with any stopwords or non-alphanumeric characters removed\n",
    "def no_alpnum_no_stopword(reviews):\n",
    "    new_reviews = []\n",
    "    for review in reviews:\n",
    "        # Tokenize\n",
    "        tokens = word_tokenize(review.lower())\n",
    "        # Remove non-alphanumeric characters\n",
    "        review_tok_alpha = [t for t in tokens if re.match(\"^[a-zA-Z]+$\", t)]\n",
    "        # Remove stopwords after removing non-alphanumeric characters\n",
    "        #review_stopwords = []\n",
    "        #for t in review_tok_alpha:\n",
    "        #    if t not in stopwords.words('english'):\n",
    "        #        review_stopwords.append(t)\n",
    "        review_stopwords = [t for t in review_tok_alpha if t not in stopwords.words('english')]\n",
    "        # Re-form the tokens\n",
    "        review_text = \" \".join(review_stopwords)\n",
    "        #print(review_text)\n",
    "        # Append to new_reviews\n",
    "        new_reviews.append(review_text)\n",
    "    return (new_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the function on our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New version of the train set (just modifying the sentences, not the tags)\n",
    "train2_sentences_sw = no_alpnum_no_stopword(train2_sentences)\n",
    "#print(train_sentences_sw[0])\n",
    "# New version of the test set (just modifying the sentences, not the tags)\n",
    "test2_sentences_sw = no_alpnum_no_stopword(test2_sentences)\n",
    "#print(test_sentences_sw[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analysis of Results\n",
    "\n",
    "A) Evaluation methods used are accuracy, precision, and recall for each propaganda type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B) Individual Results\n",
    "\n",
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat earlier steps from 5. when setting up and training multinomial Logistic Regression Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect_sw = CountVectorizer()\n",
    "train2_counts_sw = count_vect_sw.fit_transform(train2_sentences_sw)\n",
    "test2_counts_sw = count_vect_sw.transform(test2_sentences_sw)\n",
    "\n",
    "clf_lr2_sw = LogisticRegression(solver='lbfgs', multi_class=\"multinomial\", max_iter=1000, random_state=1)\n",
    "\n",
    "clf_lr2_scores_sw = train_model(clf_lr2_sw, train2_counts_sw, train2_tags, 1)\n",
    "print(clf_lr2_scores_sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: \", clf_lr2_sw.score(test2_counts_sw, test2_tags))\n",
    "\n",
    "def precision(actualTags, predictions, classOfInterest):\n",
    "    actualCounter = 0\n",
    "    predCounter = 0\n",
    "    for i in range(len(predictions)):\n",
    "        if classOfInterest == predictions[i]:\n",
    "            predCounter += 1\n",
    "            if classOfInterest == actualTags[i]:\n",
    "                actualCounter += 1\n",
    "    if (predCounter == 0 ):\n",
    "        return 0\n",
    "    else:\n",
    "        return actualCounter/predCounter\n",
    "\n",
    "def recall(actualTags, predictions, classOfInterest):\n",
    "    actualTagCounter = 0\n",
    "    predictionsCounter = 0\n",
    "    for i in range(len(predictions)):\n",
    "        if classOfInterest == actualTags[i]:\n",
    "            actualTagCounter += 1\n",
    "            if classOfInterest == predictions[i]:\n",
    "                predictionsCounter += 1\n",
    "                \n",
    "    if (actualTagCounter == 0):\n",
    "        return 0\n",
    "    else:\n",
    "        return predictionsCounter/actualTagCounter\n",
    "\n",
    "\n",
    "y_pred = clf_lr2_sw.predict(test2_counts_sw)\n",
    "\n",
    "print(\"\\nPrecision Values for Each Class:\")\n",
    "print(\"Appeal_to_Authority: \", precision(test2_tags, y_pred, \"Appeal_to_Authority\"))\n",
    "print(\"Doubt: \", precision(test2_tags, y_pred, \"Doubt\"))\n",
    "print(\"Repetition: \", precision(test2_tags, y_pred, \"Repetition\"))\n",
    "print(\"Appeal_to_fear-prejudice: \", precision(test2_tags, y_pred, \"Appeal_to_fear-prejudice\"))\n",
    "print(\"Slogans: \", precision(test2_tags, y_pred, \"Slogans\"))\n",
    "print(\"Black-and-White_Fallacy: \", precision(test2_tags, y_pred, \"Black-and-White_Fallacy\"))\n",
    "print(\"Loaded_Language: \", precision(test2_tags, y_pred, \"Loaded_Language\"))\n",
    "print(\"Flag-Waving: \", precision(test2_tags, y_pred, \"Flag-Waving\"))\n",
    "print(\"Name_Calling,Labeling: \", precision(test2_tags, y_pred, \"Name_Calling,Labeling\"))\n",
    "print(\"Whataboutism,Straw_Men,Red_Herring: \", precision(test2_tags, y_pred, \"Whataboutism,Straw_Men,Red_Herring\"))\n",
    "print(\"Causal_Oversimplification: \", precision(test2_tags, y_pred, \"Causal_Oversimplification\"))\n",
    "print(\"Exaggeration,Minimisation: \", precision(test2_tags, y_pred, \"Exaggeration,Minimisation\"))\n",
    "print(\"Bandwagon,Reductio_ad_hitlerum: \", precision(test2_tags, y_pred, \"Bandwagon,Reductio_ad_hitlerum\"))\n",
    "print(\"Thought-terminating_Cliches: \", precision(test2_tags, y_pred, \"Thought-terminating_Cliches\"))\n",
    "\n",
    "print(\"\\nRecall Values for Each Class:\")\n",
    "print(\"Appeal_to_Authority: \", recall(test2_tags, y_pred, \"Appeal_to_Authority\"))\n",
    "print(\"Doubt: \", recall(test2_tags, y_pred, \"Doubt\"))\n",
    "print(\"Repetition: \", recall(test2_tags, y_pred, \"Repetition\"))\n",
    "print(\"Appeal_to_fear-prejudice: \", recall(test2_tags, y_pred, \"Appeal_to_fear-prejudice\"))\n",
    "print(\"Slogans: \", recall(test2_tags, y_pred, \"Slogans\"))\n",
    "print(\"Black-and-White_Fallacy: \", recall(test2_tags, y_pred, \"Black-and-White_Fallacy\"))\n",
    "print(\"Loaded_Language: \", recall(test2_tags, y_pred, \"Loaded_Language\"))\n",
    "print(\"Flag-Waving: \", recall(test2_tags, y_pred, \"Flag-Waving\"))\n",
    "print(\"Name_Calling,Labeling: \", recall(test2_tags, y_pred, \"Name_Calling,Labeling\"))\n",
    "print(\"Whataboutism,Straw_Men,Red_Herring: \", recall(test2_tags, y_pred, \"Whataboutism,Straw_Men,Red_Herring\"))\n",
    "print(\"Causal_Oversimplification: \", recall(test2_tags, y_pred, \"Causal_Oversimplification\"))\n",
    "print(\"Exaggeration,Minimisation: \", recall(test2_tags, y_pred, \"Exaggeration,Minimisation\"))\n",
    "print(\"Bandwagon,Reductio_ad_hitlerum: \", recall(test2_tags, y_pred, \"Bandwagon,Reductio_ad_hitlerum\"))\n",
    "print(\"Thought-terminating_Cliches: \", recall(test2_tags, y_pred, \"Thought-terminating_Cliches\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat earlier steps from 5. for Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Decision Tree classifer object\n",
    "clf_dt2_sw = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf_dt2_sw = clf_dt2_sw.fit(train2_counts_sw,train2_tags)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf_dt2_sw.predict(test2_counts_sw)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy:\", metrics.accuracy_score(test2_tags, y_pred))\n",
    "\n",
    "print(\"\\nPrecision Values for Each Class:\")\n",
    "print(\"Appeal_to_Authority: \", precision(test2_tags, y_pred, \"Appeal_to_Authority\"))\n",
    "print(\"Doubt: \", precision(test2_tags, y_pred, \"Doubt\"))\n",
    "print(\"Repetition: \", precision(test2_tags, y_pred, \"Repetition\"))\n",
    "print(\"Appeal_to_fear-prejudice: \", precision(test2_tags, y_pred, \"Appeal_to_fear-prejudice\"))\n",
    "print(\"Slogans: \", precision(test2_tags, y_pred, \"Slogans\"))\n",
    "print(\"Black-and-White_Fallacy: \", precision(test2_tags, y_pred, \"Black-and-White_Fallacy\"))\n",
    "print(\"Loaded_Language: \", precision(test2_tags, y_pred, \"Loaded_Language\"))\n",
    "print(\"Flag-Waving: \", precision(test2_tags, y_pred, \"Flag-Waving\"))\n",
    "print(\"Name_Calling,Labeling: \", precision(test2_tags, y_pred, \"Name_Calling,Labeling\"))\n",
    "print(\"Whataboutism,Straw_Men,Red_Herring: \", precision(test2_tags, y_pred, \"Whataboutism,Straw_Men,Red_Herring\"))\n",
    "print(\"Causal_Oversimplification: \", precision(test2_tags, y_pred, \"Causal_Oversimplification\"))\n",
    "print(\"Exaggeration,Minimisation: \", precision(test2_tags, y_pred, \"Exaggeration,Minimisation\"))\n",
    "print(\"Bandwagon,Reductio_ad_hitlerum: \", precision(test2_tags, y_pred, \"Bandwagon,Reductio_ad_hitlerum\"))\n",
    "print(\"Thought-terminating_Cliches: \", precision(test2_tags, y_pred, \"Thought-terminating_Cliches\"))\n",
    "\n",
    "print(\"\\nRecall Values for Each Class:\")\n",
    "print(\"Appeal_to_Authority: \", recall(test2_tags, y_pred, \"Appeal_to_Authority\"))\n",
    "print(\"Doubt: \", recall(test2_tags, y_pred, \"Doubt\"))\n",
    "print(\"Repetition: \", recall(test2_tags, y_pred, \"Repetition\"))\n",
    "print(\"Appeal_to_fear-prejudice: \", recall(test2_tags, y_pred, \"Appeal_to_fear-prejudice\"))\n",
    "print(\"Slogans: \", recall(test2_tags, y_pred, \"Slogans\"))\n",
    "print(\"Black-and-White_Fallacy: \", recall(test2_tags, y_pred, \"Black-and-White_Fallacy\"))\n",
    "print(\"Loaded_Language: \", recall(test2_tags, y_pred, \"Loaded_Language\"))\n",
    "print(\"Flag-Waving: \", recall(test2_tags, y_pred, \"Flag-Waving\"))\n",
    "print(\"Name_Calling,Labeling: \", recall(test2_tags, y_pred, \"Name_Calling,Labeling\"))\n",
    "print(\"Whataboutism,Straw_Men,Red_Herring: \", recall(test2_tags, y_pred, \"Whataboutism,Straw_Men,Red_Herring\"))\n",
    "print(\"Causal_Oversimplification: \", recall(test2_tags, y_pred, \"Causal_Oversimplification\"))\n",
    "print(\"Exaggeration,Minimisation: \", recall(test2_tags, y_pred, \"Exaggeration,Minimisation\"))\n",
    "print(\"Bandwagon,Reductio_ad_hitlerum: \", recall(test2_tags, y_pred, \"Bandwagon,Reductio_ad_hitlerum\"))\n",
    "print(\"Thought-terminating_Cliches: \", recall(test2_tags, y_pred, \"Thought-terminating_Cliches\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Comparative Results:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2 Results:\n",
    "\n",
    "Logistic Regression: Accuracy : 0.56 Precision (Best Class - Name_Calling,Labeling): 0.70 Recall (Best Class - Loaded_Language): 0.88\n",
    "\n",
    "Decision Tree: Accuracy: 0.47 Precision (Best Class - Name_Calling,Labeling): 0.63 Recall (Best Class - Loaded_Language): 0.72\n",
    "\n",
    "Logistic Regression: + NLP: Accuracy : 0.51 Precision (Best Class - Appeal_to_fear-prejudice): 0.58 Recall (Best Class - Loaded_Language): 0.88\n",
    "\n",
    "Decision Tree + NLP: Accuracy: 0.44 Precision (Best Class - Loaded_Language): 0.59 Recall (Best Class - Flag-Waving): 0.72"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, Logistic Regression performed better than Decision Trees on Task 1, However on Task 2 (Before feature engineering) they had a similar performance.\n",
    "\n",
    "After Feature engineering, Logistic Regression and Decision Trees still had similar performance. Therefore, overall, Logistic Regression performed better than Decision Trees because in Task 1, it performed significantly better than Decision Trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[0] : https://propaganda.qcri.org/semeval2020-task11/\n",
    "\n",
    "[1] : https://blog.bigml.com/2016/09/28/logistic-regression-versus-decision-trees/\n",
    "\n",
    "[2] : https://stackoverflow.com/questions/678236/how-to-get-the-filename-without-the-extension-from-a-path-in-python\n",
    "\n",
    "[3] : https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model\n",
    "\n",
    "[4] : https://datascience.stackexchange.com/questions/17516/how-to-deal-with-string-labels-in-multi-class-classification-with-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
